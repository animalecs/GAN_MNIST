{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_MNISET.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzAty0AGfzElz9dRrQpMc6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/animalecs/GAN_MNISET/blob/master/GAN_MNISET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U5nPec0ja1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "# Without this the model will doesn't compile\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt45um4fjixE",
        "colab_type": "code",
        "outputId": "ee9fb064-a331-4603-ed0e-d19627484110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load dataset\n",
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuLUoxvRj_pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape the image to 28x28x1 (black and white)\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "# Normalize data between the range [-1, 1]\n",
        "train_images = (train_images - 127.5) / 127.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWEJumP0knic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Size of the buffer taken from the dataset to shuffle\n",
        "BUFFER_SIZE = 60000\n",
        "# Size of the batch we train per time\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zACzPxbk-y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym81ndkVlpZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generator_model():\n",
        "  \"\"\"\n",
        "  Creates the generator model\n",
        "\n",
        "  Returns:\n",
        "  model: the freshly created generator model\n",
        "  \"\"\"\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100, )))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((7, 7, 256)))\n",
        "  # Ensure the data has the right size, None is the size of the batch\n",
        "  assert model.output_shape == (None, 7, 7, 256) \n",
        "\n",
        "  # Conv layer, since padding is set to same the ouput size is (input_h*stride, input_w*stride, number_of_filters)\n",
        "  model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 7, 7, 128)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 14, 14, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  # This last layer has the size of the output we want to generate\n",
        "  model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCO_wZvbn_0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = make_generator_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPndz1GLKPce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_discriminator_model():\n",
        "  \"\"\"\n",
        "  Creates the discriminator model\n",
        "\n",
        "  Returns:\n",
        "  model: the freshly created discriminator model\n",
        "  \"\"\"\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  # Regularization\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Flatten())\n",
        "  # The output of the model is True/False, just 1 neuron\n",
        "  model.add(layers.Dense(1))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IR1zzxZoFbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = make_discriminator_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTCzYHOqonZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss function, in this case is binaryCrossentropy since this is a binary classification problem\n",
        "# It's defined outside of the functions because it's used in both models \n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1hKs_TCjvRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "  \"\"\"\n",
        "  Defines the loss function for the discriminator\n",
        "\n",
        "  Returns:\n",
        "  total_loss: the loss function just created\n",
        "  \"\"\"\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "  \n",
        "  return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKqATVgOmLPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "  \"\"\"\n",
        "  Defines the loss function for the generator\n",
        "\n",
        "  Returns:\n",
        "  the loss function just created\n",
        "  \"\"\"\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TSaZ6TwmWm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defines the optimizers for each model\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKfnZPlGm5_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We use checkpoints in order to save the steps made while training in case of a failure\n",
        "# of the system while processing\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAvDmEb1nYEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "# Dimension of the input noise for the generator\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 10\n",
        "\n",
        "\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhk_GX_-ojL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "  \"\"\"\n",
        "  Defines each step of the training step\n",
        "  \"\"\"\n",
        "  noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    # Generate the image starting from the noise\n",
        "    generated_images = generator(noise, training=True)\n",
        "\n",
        "    # Pass the real images and the generated images to the discriminator\n",
        "    real_output = discriminator(images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "    # Calculate losses\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "    # Calculate gradient\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    # Optimize params\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0CeyLq3rEDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  \"\"\"\n",
        "  Train the models\n",
        "\n",
        "  Arguments:\n",
        "  dataset: the dataset containing all the images\n",
        "  epochs: # of iterations on the dataset\n",
        "  \"\"\"\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKMwwqy4rJpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  \"\"\"\n",
        "  Generates random images and saves the charts\n",
        "\n",
        "  Arguments:\n",
        "  model: the model of the generator\n",
        "  epoch: number of epoch of this images\n",
        "  test_input: random seed\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST4p699xrMZu",
        "colab_type": "code",
        "outputId": "819dac20-88c0-4648-dbc8-d2952f37e598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAACvCAYAAAD+HzLWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2dd5RU1R3HPzPbKLs0d0EEpImoKBYg\nAhYUpAQlEJUkxpggxpYTEz2iEtQYc6xYImoUVEI0GpWi2I2KBSwQCFIUBUREsdH7LrvsTP54fu+b\nLSwzuzOz+5bf5xzOLrNT7p337v397q+GotEohmEEg3BtD8AwjPixBWsYAcIWrGEECFuwhhEgbMEa\nRoCwBWsYASKzqj9mZGREASKRSHpGk2Si0WgonuftL/MECIfD0R9ek7oB7YVQyBtmdnY22dnZ7neA\n3bt3k5WVBcCuXbsAKCkpAbzrotdGIpH9+ppWuWCDOtlE2V/mCbWzUMt/dklJCQ0bNgSgWbNmAGRk\nZPDVV18B3uLd22vjpb5e0yoXrGGkgnA4zODBgwEYPXo0AC+++CIPPPBAbQ4rENgZ1jACRKgqVSMU\nCiVdfwqHw/Tq1QuACy64AIDnnnuOt99+G4CdO3cm7bPiPdulYp57+ZyUqKSJnGHTNdeq6NChA++9\n9x7gq7/9+/fniy++2Odr69o1TRV7m6dJWMMIECmXsC1atADgww8/BODggw+u8JxIJMKWLVsAOPLI\nIwH49ttva/rRadmNZdnMyckBoEePHgCcd955/PjHPwbKGlZkDCktLQXgk08+AeDee+/lqaeeAmDP\nnj0JjaGuS9hw2JMLP//5zwG4//77ady4MeCdXQFGjhwZl/YRVAmr7wB8A1pV8zUJaxj1gKRaiWWq\nb9euHXfddRcAZ5xxxj5fFw6Had68OQDvv/8+gJNOn376aTKHWCny8e1rh2/QoAEATzzxBADDhw8n\nIyOjRp+t8/yjjz7qpPTkyZNr9J51hZtvvhmAK664AvC/P4CioiLAs1+kG0m7zMxMp/00adIE8FxO\n69evLzPGRF1E7du3B+DKK69k8+bNABQXFwPePdOyZUsA/vGPfwBw0003xf05SV2wGtSmTZvYsWNH\nmUHsSyXQopHK/NZbb7n/y4GeKuI1BHXo0AHwN5PYOVX2nnpfzU0/K2PPnj288MILcY0jCJx++ulc\ndtllgL+Ri2g0SmFhIQCjRo0CoLCwkPnz5wPw9ddfA/69E/tdJgO9b3FxMZs2bQL8a9OnTx9OPfVU\nADp16gTgxnXTTTdVuqgaNWoEwKRJkwA47bTTANi2bRt/+ctfyrzHqlWr3PtPnTrVzS9eTCU2jACR\nEqNTmzZtuOGGGwA4++yzAX8XKioqYvbs2YAfgjZo0CCnEpenY8eOcZn7KyOZBopwOMzFF18MwJ13\n3gl4Kt5jjz0GwCWXXAKUjdJR2F3//v0BT+0tKCjQZwK+8Wns2LHuGJGoNKkLRifNR4alRx991M2/\nukj6HXvssXz55ZdA6oxO0paefvppd4zTESXmPStoTZFIxL1Wf5Mqfc455zijmq5z+feLfV0sZnQy\njHpASkITi4uLnbvi448/BuCAAw4AYNasWVx99dWAv4ONHDmSiRMnAhXPhbm5uakYYrVYuXIlAGvW\nrAHgoYce4p577tnr83WmnzVrFgAbN250ElZnoQ8++ACACRMm1Gqcb02R8UbfR2XStTLbhSSP3GOx\n6D1kD0kluh7z5s2jX79+ZcYUa1gsb4eIvV91vc8//3wAnn/++X25bhIeZ0oW7MaNG5k2bZr3AZne\nRyxevBiA119/3Q1UhoeHH36YOXPmAL5fUsg/WxeQ4aB3796AZ1SIBxnNpkyZwtixYwH4/PPPAbj8\n8svLPCeIhEIhRo4cCeAsoLFs3LgR8C3Cf/jDHyqNaNMC0dFDx4vi4uIqDXzJZOLEiRx11FEA/Oxn\nPwP8RRkKhdzC1vXatWuXO7JdeeWVAO5ers6C3Nc8TSU2jACREgkbiUT4/vvvAT9qZ1/RHStWrCjz\nfO00W7duTcUQEyYSibB9+3Yg8Z1Tav1RRx3FZ599BsAf//hHABYuXJjEUdYO2dnZTirqu4lEItx7\n770AjBkzxj1WFZJa999/f5nHGzVq5DS1VLNjxw7uuOMOwI8hkGpeWlrK6tWrAbj11lsBTwOUBiEt\nMtFItVj29R2ZhDWMAJGybUu75YMPPhjX87VDl99Jmzdv7iRbqog30imRiJfs7GxeeeUVAE455RT3\nuHZfxUoH2dCkeOAtW7a466bvqFOnTs4VU1OKiopq7CJKBF2bVatWAXD00UcD3rVbu3Yt4M994MCB\nzpB47rnnpnxsJmENI0Ck/GAgJ3JseJ52427dugHw8ssv07p160pf36NHj6Tt1HujulIuMzPThd0p\njG3GjBkAdO7cudLXSFIohlguoiCi7KJYrWjZsmWAH16YDCKRiLuP0oGs/y+//DLgX9u8vDz69u0L\nwIknngh4lm25pk444QQAnn322dQNTnGalf0Dosn6l52dHc3Ozo5ec8010T179kT37NkTjYd//vOf\n1f7MquaWjHn26NEjumbNmuiaNWuikUgkGolE4ppTNBqNbt++Pbp9+/ZoZmZmNDMzs0bfbbzzTNY1\nLSgoiBYUFESXL18eXb58ebS0tNT9W7p0aXTp0qXRrKyspN076bymQDQUCkVDoVC0VatW0VatWkVn\nzZoVnTVrVrSoqKjKa7p+/fro+vXro40bN442btw4JfM0ldgwAkTKVWKpwspQGDt2bIWUtJKSEmcS\nP+iggwA/3UkxyHWRJUuW8MgjjwBe3CjgjBLPPvssBx54IIALKmjatKkzOmleCxYsALwsEQWS1FXk\nalNRAqm9eXl5znWleV177bUuUyVo/CChXay7XIslJSUuuCM24kkqsaK9VO5owIABcQfXxItJWMMI\nECkrESNjjPIdx48fD/jmcPBD/S688EIOPfRQAP72t78B/i4+YcIExo0bV60xRNNQTqR8KFm8rh9l\n/CicDXx3grSMeIl3npD4XCVJDjzwQI455hjAH/Oxxx4LeBJW30NsGJ+0iV//+tcAPPnkk4l8dKWk\n45pqzjIcPv/88wB06dLFSV+5GpctW+aul3K5ZYQrLS11yemJaht7m2dKFmzbtm3dQEeMGAF46uAP\nA+H2228HPLXph89xET+K41TAd9euXatd3ykdF7e66FiggPHYha9Uw3jjqFO5YJWgMX78eGcFzc/P\nB/yEjoYNG1aapF8+UH758uUAHHHEEQlXcUi08n8yFuyQIUMAL+UOPGEjNfnuu+92P/V8WZOV7NGs\nWTN3fbt27QoQd6ro3q6pqcSGESBSUtNpzJgxDBo0CPCNR5Lk8+fP509/+lOZ14VCIRctIrQDq75O\nfUOGirlz5wI4/x74JWiSoULWFPmNc3NzycvLA3B1itatWwdAQUGBM7joum3YsMEZoGR8kwQaN26c\n08CqQlpIVlZWWiPCJDFVAVMq7p49e5x6fNtttwGUMRRKS5Tm8cEHH3DccccBvk/3+OOPr1HknklY\nwwgQSZWwkpIFBQVuZ1beo+oSq1xKLC1atChzUAdfutQk86EuozOrckS7d+/udmhFS9Umkm4yqDRq\n1Mi5NGQ4lCTKyclxZzWV/7n++utdc6suXboAMGzYMKBsIr/cHiUlJRUyumKLpaWzuZU+S9UPdW/u\n2rWL6dOnA1QZeaXXjx49mldffRXwtYyOHTuyZMmSao/NJKxhBIikSFhZEidMmAB4O6l2XLlkKiul\nol38qquuqnAGqmm937pIKBRyVvMzzzwTwMVQz5w50+3edUGrkIbUsWNHwCusJ+1HLjdJ2szMTCcp\nlRu6bds2J4WUQ/ruu+8C8Lvf/Y6rrroK8DWwOXPmuHOhAjL0eek8v4J/78mNpXty9+7dvPHGG/sc\nk7Snpk2bOhuOajJff/31rpJFdeaVlAWrQ7bM4BkZGW7QqtVaGXLhjBo1qoJKLD9lXSYjI6PCl655\nx1bJa9OmDQDPPPOMuwnEhg0bAO9mfuedd4C60dtU81BqWceOHStEM8XWYdIC1/fRoUMHV8dZ7Vdk\nTMvPz3duPm1Oq1atcsasyioMppPy6Zb6/7p161zaqB4Lh8Pu+1CFUKWKtmrVyn2PKn2k4urVxVRi\nwwgQSZGwUn0U7JCTk+PUoMq6aWunVqX7/Px8t5upOJl+1mU6dOjA6aefDniFxcDfeV9//XUWLVoE\n+DWL27Vr56SnSuioHMqECRPcMaK2CYVCTi2UqhtrZNERKNY4pJQytVoJh8McfvjhgC+lZVR75513\n3PegYIrNmzfXiaMA+FJfcd7t2rUDPIOaNAl9B2PGjHGF9CRpdQ9s3LjRRYWpLUdN52gS1jACRFJC\nE7WjDBgwAPBig+VUlyFK4YWtWrXivvvuA/xggVAoxJtvvgng+rEkIwE6HaGJ2mkVbjl8+HDAO5vq\nvKOfe/bs4V//+hcAr732GuBL2pqc21IRmqizl8qW9ujRw41RmtR3330HeNdKmlRl91P5M2FNjEjp\nDDeVUU1F5FavXu00D3U46NOnjzMoaV4qLXPqqae6dZAoaY0l7t27t1uUMrLEBoXrBpZF8dJLL3XN\nr6pbmbAyaiOWWBbAxx57zKl9MqacddZZLF26FKidTvNQ/eD/7Oxsp7Kn22obS21cU1l6P//8c/e7\nFu7OnTtdSuXQoUMBXIWUmhgPLZbYMOoBKZGwGRkZLrNDEUuxFeGlDp533nmAJ4FSsWvXZrbOsGHD\nGDhwIOD7oFevXl2r84S615k8UWrzmvbs2dM1eZMUvfnmm1NSAdMkrGHUA1KWwF4XqMv5sMnEJGxF\n6us8TcIaRoCwBWsYAcIWrGEECFuwhhEgqjQ6GYZRtzAJaxgBwhasYQQIW7CGESBswRpGgLAFaxgB\nwhasYQQIW7CGESBswRpGgLAFaxgBosqqieFwOAq1WxKkJsSbipWMecbWqdX/VWs5tpaRquYlo76R\nSCS9zq5pMNjbPKtcsEGdbKIkadGU+RkOhys8Fts/prao7c9PF/V1nklthmX4LRlyc3NdK0LV9K1v\nN1H5aoixj4VCob3Ot759D+nEzrCGESDqhIQNhUKuarp2X0mnoOzGkqzqqzJkyBB+85vfAH4d36Aj\n6XnooYcC8KMf/Qjw1P+PPvoIwFX779+/v2vgrJKuKvv54osv8uKLLwLwzTffAMG5zkLNywcPHsyo\nUaMAr3cS4Log1KRx894wCWsYASJtRdhkMe3QoYMrgdq7d2/AK8CsFoYqynzOOecAuP401SEdBbs0\nL/VQue666wDYsmULRxxxBFCznVZSbW//BygtLU15IfHjjjuOBx98EPC7DqrrAVTsGRMKhdxrVYBc\n3QEKCwud1vH3v/8d8HoMxdP9oDaKsGkeLVu25O677wa8ovDgfQdaQ2pgrW59NbnuVoTNMOoBaTvD\najd+8MEHOfHEE8s8FmtR7Ny5MwDPPfccANdeey1PP/004PeoqUuodcM111wD+B3MiouLy3R82xvy\n23bs2JEuXboAfruP4cOHu7OSzoF33HEHAI8++qjrLJdKpA3NnDmT5s2blxmzqExLi0QiTsJMmzYN\n8KVpTk6OK7LetWtXAA477DA+/vjjFMwgcTS/goICwO8wOHToUHc9YjUd/a6Oi6m8T9O2YGVEeued\ndzj55JOBytU7qZht27YFYMqUKa6lo4w4daUtI/g3q3qtaE4zZsyotLWgnqcO7JdeeingNV5asmQJ\ngDPWNG7c2LU3lDrZvn17wFvA8WwI1UXzkEElNze3wkKVEWnnzp2sX78e8OcXDoeZOnUqAA888ADg\nG5iysrLcjX/GGWcAXsvRytxE6UKfnZGR4b7j8ePHA34j6pycnErv2a1btwK4rvKVtVhNFqYSG0aA\nSJuE1W7ctGlTtwvHsjfjSjgc5he/+AXgGawATjrppDrT/PeCCy4AIC8vD/DHfc4557jWmdIIQqEQ\nxx57LOAbqeQG2bx5M7169QI89Rhw0hV8zUNGj1S7ijQPuW5iDUySgBs2bAA8VfChhx4CfClaVFTk\n2lFKE5BhsW3btvTr1w/wWzrm5ua6Oabz6JOVlQXgDITjx493bqv8/HyAMver7mN9B8XFxU67UJvJ\nVGoIJmENI0CkPXBixIgRlUpYod2psrOCOuDVFekaCoW44oor3O/lKR9LHI1G+d///gfAaaedBsDR\nRx8NQLt27ZxBKTc3173Hli1bAM8oA1S7QXCi6Lx68MEHV/ibNAbZJRo1auSk57x58wBPquqxESNG\nAL4xLRqNute+/fbbgDdPSbt0SdhQKOTuKTUe79Onj7u/9FNn1JycHKfZSDPIyMhg165dAGkxAqZt\nwUrdadOmTQWVoaioyN3IsrT99Kc/BXxVE3DPqSuEw+Ey44vlk08+qdQ4prnrwr/33nuA57vTDa7F\nv3XrVg444IAyr0sX5Y1d0WjU/S5fuebQsGFDZxAcNmwYACtXrnQbs7wCsroWFhYyY8YMwL/Je/fu\nzUknnQT4EUOfffYZULPGyFURCoVchJoWYHFxsWsfqTEuW7bMjbVnz56Ab4xr0qQJH3zwAUBcfuSa\nYiqxYQSItElYmcoLCwvdTvTpp58CcNtttzlVSlEi8v/FZr2MGzcuXcONiwYNGlRwRWzcuBHwx78v\nJMkmTZrkdnupYpVpI+lC/mSp5A0bNnSqoYxJknz5+fnOfx5rrFLkT6yBBmDp0qW8/vrrAPTo0QOA\nkSNHOlfegAEDALjxxhsBeP/991MiZSORiGvMfO+99wLQr18/ZzyShJcm0ahRozJuKM135syZSR/b\n3jAJaxgBIuUSVmcDnQcaNWrESy+9BMCFF14IeGfYpk2bAnD++ecDnnQBb3fWWahVq1aAv/PVFpIi\n33zzjXN3yMk+duzYuN6jWbNmgCdtwA8UAV+qyZiRTOIJTgiFQi5eWOfq3NxcpwFI+mp8LVu2rBA4\nEo1G+frrrwH/nK57IS8vzwUZKNKpWbNmbkw688pItXjx4oTjcuMNwpCBa/r06YBnl5C2oOAWjad1\n69YVgkdKSkq4/vrrAXjjjTeA1BpFTcIaRoBImYTVDqedVI7pkpISJ221+/Xo0YP77rsPgG7dunkD\n+8GqHAqF3C6YivzC6qCY2CZNmjhpGK9kPf744wFcPqjOQrFMmTIlGcOslHjOxNFolM2bNwN+nm8o\nFHJuF527Y91zkiqSqrfccgsffvghgHsvBWHcfPPNtGvXDvDPwWvXruWee+4B/O9mzZo1QPWsr4me\n/WUnWbBggdMuFO8ca73X+2q+xcXFTiIPHjwYwGmQqSBlC1bRIoro0QLesWOHW7wyMF100UVORdRC\nFdFo1C2KdPi5qkI3rCKStm3b5iKXqkJzX7RokZtzPDGptYmOHa+99hoAp59+ultcUgtlfPryyy+5\n/fbbAXj33XcB75ijm7t8Mbq8vDy32GWIGjp0qDNC1iYrVqxwMd1C845EInz//feAn0qXl5fn/Oby\nrcuAqkiwZGIqsWEEiJRI2EaNGvHwww8DfgxqbDXB3/72t4CvbmVkZFSI0ZQEKikp4fe//z3gq0i1\nhdQgZQ/t3LnTSRtJX6lv0WjUpctJ3ZfWEYvmvWHDBg466CD32tpGrgwVEsjLy6sgYXVE2Vc1SB1p\n5EJZtWqVS0tcuXIlQJ2QruCN9d///jeAk6aKRps9e7bTqJRl1bp16wppdZK4JmENYz8nKRJW0lCH\n9blz55bJ7gA/Y6O0tJSFCxcC3o4F0LdvX3dgF9rNJ0yY4IwQdUHygD+XOXPmcMwxxwCVn0nLU5Xx\npG/fvmkJbUsUnTEVEFITpKGUlJQ4w5XcWVWVRU03Gud//vMfAN58803AM5opA0vaUzgcpnv37oBf\nmG3x4sWAd85N9jVNSk0nRX/I+pudne2+/C+++ALwg6ufffZZd2DXTX7FFVc4P2asgQagZ8+e1Y5y\nSXb9H41NRqe5c+fGtVA1/kWLFjkruDY0qZ75+fnVTnxOpPJ/MmsdJYoMTYWFhe4IIUvycccdF9d7\n1EZNJ8UIrFy50lmMYzs8CKnE8sdecMEFLi45Uaymk2HUA2qsEnfq1Iknn3wS8A0vkUiExx57DMCp\nEJUlXEsKy98FsHz5csD3V6YqU6M6aLz//e9/Ac/goOwNpdnJZdW8eXNndPjVr34FeD5KlUs55ZRT\nAH+nrkvzTBWPPPII4Ll5JI2krdRlVEAhOzvb+ZR1LzRt2tSp97r/Bw0aBHi+aBmnklXOxySsYQSI\nap9hJRnefvtt+vTpA/hS4tVXX3XO/6pyGpXBs3DhQpeYLRN6Mgqt1cZ5Zy/vD3jnVrm7Ro4cCfia\nR8eOHasdyVXXz7Ayxsgt16BBAxcXrgijeEnnNZXklLutqKjIaU26pocffriLbCrvlvv+++/d2Vwu\nonixM6xh1AMSPsNKssoSFpv3Kef3xIkTK+xEsWUkVZVA59ycnBwXg1qXSpgmC+24zZs3L1MxHvxd\nvHv37i6rpb6gABnV9dVcH3nkkYQla7rIyMhw96pcMvJ0VMaSJUucFJ0/fz7gZ5o1adLEBc388pe/\nBGqeyZPwgpXY10INh8NuYroJL774Ynfw1mFb/raBAwe6gtSKMY1EIs7XVZ8pLCys4J/WzTFkyJDA\nLNjYzRe866eNXCVtZs6c6QyHer7uBS3gukpstFo8yEc9ZswYANfSJC8vz8W/JyvlzlRiwwgQCRud\n5ESWmqD/g6/OFhcXu91Jyc6xCc7lP3Pp0qUMHToU8NOzkkFdMTrFfI4zOilRX5Lpq6++cvWIE42O\nSaXRKTZhW5JS11QurcMOO8wFz5x66qlA2Sr5KtqmhPAFCxYkMoQypOqaxgZAJBpxpdcqzU7aYvPm\nzV2Rhqeeeiqh9zSjk2HUA6rt1lE91xkzZjhXjKRobN6qJHBs68EVK1YA/k775z//2VVPTyZ1TcLG\nohBFBWFkZma6IILy+Zj7ItkSNrZeb//+/QG/lA34wSGXXHIJ4ElcaQdi69at3HDDDYDfDCsZ57hU\nXVPZU0pLS6uUsOWzs0KhkLvvlQ87adIkwNMydJ3VESFe9jbPGscSh8NhDjnkEMAPiO7Xrx/PP/88\n4BshFDO6fft2Fy2SauryghWKme7evbtThWWgi9d3l6wFq021RYsWvPXWW4CfEpidne186bGpjz98\nvquCqJYdr7zySkqSGeKdazgcjmpsQlZqpcht2LDBFUqX4eiAAw5wse6qQaVE/Z49ezqVXymWCxYs\nqNDaQ1bizZs3u3pPivKq6TxNJTaMAJG2Duy1QRAkrBLEH3/8cfeY6vKqjcW+SIXRSa431esdMWKE\nq5KoSviTJ08G4IUXXnDlbVJNTa6pIq4UZbZ9+3ZXfkjSsXPnzq6Svwygmnd2drZT61V8Ydu2ba4+\nlX7q/Vu3bu1qFqsOWLxah0lYw6gHmISlduep8+Do0aNdBo9aWMYb9VXXY4mTSTKuaWzTad3/iQZL\nxENOTo4zZu3cuTOh15qENYx6gElY9p95wv4z1/o6T5OwhhEgbMEaRoCoUiU2DKNuYRLWMAKELVjD\nCBC2YA0jQNiCNYwAYQvWMAKELVjDCBC2YA0jQNiCNYwAYQvWMAJElXWJKyuzESTiDRTPyMiIQnAb\nUiUS/G8EmyoXbFAXaqIEdaEa+x+mEhtGgLAFaxgBosYNnQ0P1atVca5+/fq5siMq6lXddpKGIUzC\nGkaAqBUJq8JjKuzcunVrVzxbHc7Uu2fTpk11ziikIl6jR4927SPVZ6ZFixZA2R5C5513HgBPPPFE\nuodq1DNMwhpGgEh5ETZJo5/85CcAXH311a4PS7NmzQDYvXs3ixcvBmDhwoUAroXC+vXrGTduHOC3\nU4iXVBXsat26NeD1QFWfmdzc3L0+X2fX/Pz8lDSsNj/s/kPKFqyaBamp75QpUwCvOrpU4dhO159/\n/jngNw3q1KkT4DXTGjhwIOA3joqXVFfYy8zM5MgjjwRwzZjVivGHzwf8JlDTp093nbiTiS3Y/QdT\niQ0jQCRVwkqqXnfddQwePBiAVq1aAb4xJjc3t0zzXPBUYnW0k5os9wjguom1b98+keGktYZt3759\nAXj55ZcBaNKkSYXnbN++nZNPPhnAHQGSgUnY/QeTsIYRIJLq1snJyQHg4osvdpJSwQPqMQJ+X1EZ\nYzZu3OgMOZKssVJ406ZNyRxmSvj4448BWLNmDQBHHXWUO8PqZ3Z2Njt27KidARr1gqQu2MLCQsDr\nIH7CCScAvposX+p3333HnXfeCcBzzz0HeO0Vb731VoAK6jLAq6++msxhpgRtPpdffjkAN954o7OG\nyxC1devWtLVlNOonphIbRoBIqoSV+nvRRRe5+NmCgoIyf5s2bRovvfRSmdcNGzbMtaeXJJak3b17\nN7fffnsyh5kSpEnIQDZ58mQnbeVTzsvLK+P2MYxEMQlrGAEiJbHEXbt2dS3olcWihrarVq2iTZs2\nAFxzzTUA9O/fv4xRCnyJ/NVXX7lW92pvn2wkzRNN2A+Hw87Q1q5dO8A7j4NneDvssMMAX/qGQiFW\nr14N4H6effbZACxatKgmUzD2E0zCGkaASImEVZAE+JJS1tGTTz6ZUaNGAZ7rAzyXj6SczrAK5yst\nLa0gfdNBVVJXf2vRogVnnHEGAJdddhmAC1WUVC3/Or22c+fOgB/S2KtXL5YtW5bMKRj1kJTEEmdk\nZLiIn169egG+2yMrK8staMUURyKRCil0Gte6desYPXo0AG+88UaZv+2LmhRhU9JCbLyzkBp81lln\nOReVIrpi3VLlx1mZy0rPmTx5MhdddFGlr9sbMZucRTrtJ5hKbBgBIiW6ZmlpKcOHDwfgmWeeAfxY\n2wYNGjgVV8nq69atc6+VpJKxKisryxms9FistEsGVSXI628ZGRlOI1Am0SGHHOIMYnqexrZ27Vp2\n794NeO4c8Ixmito6+uijAT+ya8CAAU6NjjcFb3+pamn4mIQ1jACRMmuO4oUVECEpEw6HnRT69ttv\nAVi2bBnHHHMM4EsNSZnVq1fTrVs3AD766CMAtm3bltSxVmZgkrQbMmQIAG3btqVfv35lnterVy/n\nnvnss88AmDRpEuCFZ+7atZWElnoAAALGSURBVAvASdrY9504cSIA5557LuBlIq1YsQKALl26AP53\naBgi5eZXRflInQVcAPz8+fMBrx6SVGGpll9//TUA8+bNY+nSpUDZGz+ZVGUJVjxwmzZt3DjkR164\ncCF//etfAX8z2Ze6rkinQYMGAf73Eo1GWblyJeBbyA2jPKYSG0aASJmEldRq2bJlmceLi4tdNND6\n9esBr3RKhw4dAF/CSp2cN2+ek16pkrCVoc96/PHHAU891ZhiJWCiFR2l+isSTKxcuZKhQ4cCZkwy\n9o5JWMMIECmXsOXzYadOnerOajonfvfdd2XcJ7F8+OGHtZL0rfFIC0gG4XCYu+66q8xja9euBaBb\nt252djX2iUlYwwgQKZOwPXr0AHwrqMqX3njjje4sqBC/LVu2uOdJ6iqPVm6TVFLdbJ14kdYwbdo0\n973IZXPKKacAZhk24iNlC/bKK68E/EXw9NNPA567Rurm4YcfDkDv3r0rxOyqeHg6DE2pWqiak9p5\njBgxwv1NG9iqVatS8tlG/cRUYsMIECmTsMpikQp4//33A378MPhqb8OGDZ1kVb3eqVOnpmpoaUcp\neLHZOoreMoxEMAlrGAEi5c2w1GpRcbKLFi1yrh7F5l5yySUsWbIEgFtuuQXwS8rUhHRW/q+KQw45\nBIBPPvnEJakrWycZWOX//YeUxxJrQ3jllVcArxWHAvvlXz3zzDOZO3cuEH9qWZBQXPSXX35ZaRK7\nYcSLqcSGESBSLmFnz54N+P1TQ6GQU4mnT58OwJw5c+p1/KwMbbNnzy5jdDOMRDEJaxgBIuVGp/Jk\nZ2en7ZxaV4xOon379i66S0a4ZGBGp/0Hk7CGESDSLmHTSV2TsKFQKCVndZOw+w9VStjYwtdGzanP\nhjUjPZhKbBgBokqV2DCMuoVJWMMIELZgDSNA2II1jABhC9YwAoQtWMMIELZgDSNA/B96i+Onc2Wg\n2wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 48 is 734.9489080905914 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cywV9wH0rOGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}