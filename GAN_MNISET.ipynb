{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_MNISET.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U5nPec0ja1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "# Without this the model will doesn't compile\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt45um4fjixE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dataset\n",
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuLUoxvRj_pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape the image to 28x28x1 (black and white)\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "# Normalize data between the range [-1, 1]\n",
        "train_images = (train_images - 127.5) / 127.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWEJumP0knic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Size of the buffer taken from the dataset to shuffle\n",
        "BUFFER_SIZE = 60000\n",
        "# Size of the batch we train per time\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zACzPxbk-y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym81ndkVlpZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generator_model():\n",
        "  \"\"\"\n",
        "  Creates the generator model\n",
        "\n",
        "  Returns:\n",
        "  model: the freshly created generator model\n",
        "  \"\"\"\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100, )))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((7, 7, 256)))\n",
        "  # Ensure the data has the right size, None is the size of the batch\n",
        "  assert model.output_shape == (None, 7, 7, 256) \n",
        "\n",
        "  # Conv layer, since padding is set to same the ouput size is (input_h*stride, input_w*stride, number_of_filters)\n",
        "  model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 7, 7, 128)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 14, 14, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  # This last layer has the size of the output we want to generate\n",
        "  model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCO_wZvbn_0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = make_generator_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPndz1GLKPce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_discriminator_model():\n",
        "  \"\"\"\n",
        "  Creates the discriminator model\n",
        "\n",
        "  Returns:\n",
        "  model: the freshly created discriminator model\n",
        "  \"\"\"\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  # Regularization\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Flatten())\n",
        "  # The output of the model is True/False, just 1 neuron\n",
        "  model.add(layers.Dense(1))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IR1zzxZoFbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = make_discriminator_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTCzYHOqonZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss function, in this case is binaryCrossentropy since this is a binary classification problem\n",
        "# It's defined outside of the functions because it's used in both models \n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1hKs_TCjvRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "  \"\"\"\n",
        "  Defines the loss function for the discriminator\n",
        "\n",
        "  Returns:\n",
        "  total_loss: the loss function just created\n",
        "  \"\"\"\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "  \n",
        "  return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKqATVgOmLPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "  \"\"\"\n",
        "  Defines the loss function for the generator\n",
        "\n",
        "  Returns:\n",
        "  the loss function just created\n",
        "  \"\"\"\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TSaZ6TwmWm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defines the optimizers for each model\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKfnZPlGm5_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We use checkpoint in order to save the steps made while training in case of a failure\n",
        "# of the system while processing\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAvDmEb1nYEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "# Dimension of the input noise for the generator\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 10\n",
        "\n",
        "\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhk_GX_-ojL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "  \"\"\"\n",
        "  Defines each step of the training step\n",
        "  \"\"\"\n",
        "  noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    # Generate the image starting from the noise\n",
        "    generated_images = generator(noise, training=True)\n",
        "\n",
        "    # Pass the real images and the generated images to the discriminator\n",
        "    real_output = discriminator(images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "    # Calculate losses\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "    # Calculate gradient\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    # Optimize params\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0CeyLq3rEDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  \"\"\"\n",
        "  Train the models\n",
        "\n",
        "  Arguments:\n",
        "  dataset: the dataset containing all the images\n",
        "  epochs: # of iterations on the dataset\n",
        "  \"\"\"\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKMwwqy4rJpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  \"\"\"\n",
        "  Generates random images and saves the charts\n",
        "\n",
        "  Arguments:\n",
        "  model: the model of the generator\n",
        "  epoch: number of epoch of this images\n",
        "  test_input: random seed\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST4p699xrMZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "25bcf04b-f490-45b9-8ade-014f7798d77f"
      },
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAACvCAYAAAD+HzLWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR/wPKhi5DEz/ToUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 288x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 18 is 773.5978791713715 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cywV9wH0rOGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}